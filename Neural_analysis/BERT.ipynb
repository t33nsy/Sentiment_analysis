{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23ecbfd7",
   "metadata": {},
   "source": [
    "Подгрузим библиотеки, если нужно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e32d7984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/t33nsy/.local/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in /home/t33nsy/.local/lib/python3.10/site-packages (3.5.0)\n",
      "Requirement already satisfied: tensorflow in /home/t33nsy/.local/lib/python3.10/site-packages (2.19.0)\n",
      "Requirement already satisfied: scikit-learn in /home/t33nsy/.local/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: tf-keras in /home/t33nsy/.local/lib/python3.10/site-packages (2.19.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/t33nsy/.local/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/t33nsy/.local/lib/python3.10/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: requests in /home/t33nsy/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/t33nsy/.local/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/t33nsy/.local/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/t33nsy/.local/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: filelock in /home/t33nsy/.local/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/t33nsy/.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: aiohttp in /home/t33nsy/.local/lib/python3.10/site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: pandas in /home/t33nsy/.local/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /home/t33nsy/.local/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: fsspec[http]<=2024.12.0,>=2023.1.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from datasets) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/t33nsy/.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/t33nsy/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/t33nsy/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: rich in /home/t33nsy/.local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /home/t33nsy/.local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/t33nsy/.local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/t33nsy/.local/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/t33nsy/.local/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/t33nsy/.local/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/t33nsy/.local/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/t33nsy/.local/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/t33nsy/.local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/t33nsy/.local/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/t33nsy/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/t33nsy/.local/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/t33nsy/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets tensorflow scikit-learn tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f563ebe",
   "metadata": {},
   "source": [
    "Будем использовать предобученный BERT и также BERTтокенизатор\n",
    "\n",
    "Замечание - трансформеры еще не поддерживают версию keras-3, скачиваем keras-2.19..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f8ffa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 00:15:47.921657: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-16 00:15:47.969492: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744751747.991737   13286 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744751747.997477   13286 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744751748.014700   13286 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744751748.014722   13286 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744751748.014724   13286 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744751748.014725   13286 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-16 00:15:48.022619: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc8eb808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество доступных GPU устройств:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество доступных GPU устройств: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3133065d",
   "metadata": {},
   "source": [
    "Датасет с каггла - загружаем зависимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3bb576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kagglehub in /home/t33nsy/.local/lib/python3.10/site-packages (0.3.11)\n",
      "Requirement already satisfied: requests in /home/t33nsy/.local/lib/python3.10/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: packaging in /home/t33nsy/.local/lib/python3.10/site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from kagglehub) (5.4.1)\n",
      "Requirement already satisfied: tqdm in /home/t33nsy/.local/lib/python3.10/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/t33nsy/.local/lib/python3.10/site-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/t33nsy/.local/lib/python3.10/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/t33nsy/.local/lib/python3.10/site-packages (from requests->kagglehub) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/t33nsy/.local/lib/python3.10/site-packages (from requests->kagglehub) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aa105d",
   "metadata": {},
   "source": [
    "Загружаем интересный датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0fde2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/t33nsy/.cache/kagglehub/datasets/mdismielhossenabir/sentiment-analysis/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"mdismielhossenabir/sentiment-analysis\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61b266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "!ls /home/t33nsy/.cache/kagglehub/datasets/mdismielhossenabir/sentiment-analysis/versions/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "337e9fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+\"/sentiment_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c98cda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>morning</td>\n",
       "      <td>What a great day!!! Looks like dream.</td>\n",
       "      <td>positive</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>noon</td>\n",
       "      <td>I feel sorry, I miss you here in the sea beach</td>\n",
       "      <td>positive</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>night</td>\n",
       "      <td>Don't angry me</td>\n",
       "      <td>negative</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>morning</td>\n",
       "      <td>We attend in the class just for listening teac...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>noon</td>\n",
       "      <td>Those who want to go, let them go</td>\n",
       "      <td>negative</td>\n",
       "      <td>Instagram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  Day Time of Tweet  \\\n",
       "0  2018      8   18       morning   \n",
       "1  2018      8   18          noon   \n",
       "2  2017      8   18         night   \n",
       "3  2022      6    8       morning   \n",
       "4  2022      6    8          noon   \n",
       "\n",
       "                                                text sentiment     Platform  \n",
       "0              What a great day!!! Looks like dream.  positive    Twitter    \n",
       "1     I feel sorry, I miss you here in the sea beach  positive    Facebook   \n",
       "2                                     Don't angry me  negative     Facebook  \n",
       "3  We attend in the class just for listening teac...  negative    Facebook   \n",
       "4                  Those who want to go, let them go  negative   Instagram   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5d59c",
   "metadata": {},
   "source": [
    "Преобразовываем метки в числа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45631966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>morning</td>\n",
       "      <td>What a great day!!! Looks like dream.</td>\n",
       "      <td>2</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>noon</td>\n",
       "      <td>I feel sorry, I miss you here in the sea beach</td>\n",
       "      <td>2</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>night</td>\n",
       "      <td>Don't angry me</td>\n",
       "      <td>0</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>morning</td>\n",
       "      <td>We attend in the class just for listening teac...</td>\n",
       "      <td>0</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>noon</td>\n",
       "      <td>Those who want to go, let them go</td>\n",
       "      <td>0</td>\n",
       "      <td>Instagram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  Day Time of Tweet  \\\n",
       "0  2018      8   18       morning   \n",
       "1  2018      8   18          noon   \n",
       "2  2017      8   18         night   \n",
       "3  2022      6    8       morning   \n",
       "4  2022      6    8          noon   \n",
       "\n",
       "                                                text  sentiment     Platform  \n",
       "0              What a great day!!! Looks like dream.          2    Twitter    \n",
       "1     I feel sorry, I miss you here in the sea beach          2    Facebook   \n",
       "2                                     Don't angry me          0     Facebook  \n",
       "3  We attend in the class just for listening teac...          0    Facebook   \n",
       "4                  Those who want to go, let them go          0   Instagram   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удаляем пропуски\n",
    "df = df.dropna(subset=['text', 'sentiment'])\n",
    "\n",
    "# Преобразуем тексты в строки (на случай если там числа или другие типы)\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['sentiment'] = label_encoder.fit_transform(df['sentiment'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0996cce2",
   "metadata": {},
   "source": [
    "Делим на обучающую и тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ca59995",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['text'].tolist(), df['sentiment'].tolist(), test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c170621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c96e1",
   "metadata": {},
   "source": [
    "Токенизируем токенизатором BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884d4191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744751755.649884   13286 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors=\"tf\", max_length=128)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, return_tensors=\"tf\", max_length=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ac2f1a",
   "metadata": {},
   "source": [
    "Создаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfbaa59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    tf.convert_to_tensor(train_labels)\n",
    ")).shuffle(1000).batch(4)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    tf.convert_to_tensor(val_labels)\n",
    ")).batch(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e84f26",
   "metadata": {},
   "source": [
    "Смотрим, сколько классов тональностей у нас есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f6265c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    199\n",
       "2    166\n",
       "0    134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eb2d41",
   "metadata": {},
   "source": [
    "Количество уникальных классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2de14d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d378ab2",
   "metadata": {},
   "source": [
    "Файн-тюн предобученного BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfbc333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd5c92d",
   "metadata": {},
   "source": [
    "Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "391d5617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(label_encoder.classes_)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87865024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb32e28a",
   "metadata": {},
   "source": [
    "Компиляция модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8669cab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0 (unused)\n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  2307      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109484547 (417.65 MB)\n",
      "Trainable params: 109484547 (417.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = ['accuracy']\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ebb984",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b628371a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1744751784.098615   13535 service.cc:152] XLA service 0x7effa960a870 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1744751784.098660   13535 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-04-16 00:16:24.105543: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1744751784.120170   13535 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1744751784.201964   13535 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 52s 186ms/step - loss: 1.0544 - accuracy: 0.4411 - val_loss: 0.9905 - val_accuracy: 0.5000\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.7412 - accuracy: 0.7068 - val_loss: 0.5707 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7f01783ec070>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=val_dataset, epochs=2, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635fcbb9",
   "metadata": {},
   "source": [
    "Сохраняем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fbc9cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(filepath=\"./BERT2.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2d4e29",
   "metadata": {},
   "source": [
    "Загружаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ead698b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./BERT.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6fdbaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"tf\", truncation=True, padding=True, max_length=128)\n",
    "    logits = model(inputs)[0]\n",
    "    predicted_class = tf.argmax(logits, axis=1).numpy()[0]\n",
    "    return label_encoder.inverse_transform([predicted_class])[0]\n",
    "\n",
    "print(predict_sentiment(\"I feel hopeless and lost.\"))\n",
    "print(predict_sentiment(\"I'm okay, just a bit tired.\"))\n",
    "print(predict_sentiment(\"I'm feeling great today!\"))\n",
    "print(predict_sentiment(\"Enjoyable but could've been a lot better\"))\n",
    "print(predict_sentiment(\"Nah it's mid\"))\n",
    "print(predict_sentiment(\"It's mid\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d4f842",
   "metadata": {},
   "source": [
    "Посмотрим на ошибки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3417e8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(val_encodings, batch_size=4).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76e32afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test 0.8\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = np.argmax(y_pred, axis=1)\n",
    "true_labels = val_labels\n",
    "\n",
    "wrong_idx = np.where(predicted_labels != true_labels)[0]\n",
    "print(f\"Accuracy on test {1 - len(wrong_idx)/len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81f10361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>True Label</th>\n",
       "      <th>Predicted Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'there are people and then there are pencils' some are sharp, some are not and some can be sharpened  my pencil philosophy.....</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Screw the reviews, I thought Wolverine was awesome. But not enough Dominic Monaghan for my liking.</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I saw amazing heeels. But they were too big</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How looks like our company new logo?</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is home alone.. Doing hw</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Here`s a brief preview:   OMG James is creepy in that role! I`m scared of him</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>If u do, please pray 4 me.  Lord knows I need it.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>doing pretty well, up and wide awake</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i want to wake up early, and get a coffee tomorrow (today) !  it`s going to be a busyy day! but have to keep writing.. booo whoo!</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>can`t school just be done already? it hurts too much... seeing him every day</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                Text  \\\n",
       "0    'there are people and then there are pencils' some are sharp, some are not and some can be sharpened  my pencil philosophy.....   \n",
       "1                                 Screw the reviews, I thought Wolverine was awesome. But not enough Dominic Monaghan for my liking.   \n",
       "2                                                                                        I saw amazing heeels. But they were too big   \n",
       "3                                                                                               How looks like our company new logo?   \n",
       "4                                                                                                           is home alone.. Doing hw   \n",
       "5                                                      Here`s a brief preview:   OMG James is creepy in that role! I`m scared of him   \n",
       "6                                                                                  If u do, please pray 4 me.  Lord knows I need it.   \n",
       "7                                                                                               doing pretty well, up and wide awake   \n",
       "8  i want to wake up early, and get a coffee tomorrow (today) !  it`s going to be a busyy day! but have to keep writing.. booo whoo!   \n",
       "9                                                       can`t school just be done already? it hurts too much... seeing him every day   \n",
       "\n",
       "  True Label Predicted Label  \n",
       "0    neutral        negative  \n",
       "1   positive        negative  \n",
       "2    neutral        negative  \n",
       "3   positive         neutral  \n",
       "4    neutral        negative  \n",
       "5   negative        positive  \n",
       "6    neutral        negative  \n",
       "7   positive         neutral  \n",
       "8    neutral        positive  \n",
       "9   positive        negative  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_texts = [val_texts[i] for i in wrong_idx]\n",
    "wrong_true = [true_labels[i] for i in wrong_idx]\n",
    "wrong_pred = [predicted_labels[i] for i in wrong_idx]\n",
    "\n",
    "wrong_true_labels = label_encoder.inverse_transform(wrong_true)\n",
    "wrong_pred_labels = label_encoder.inverse_transform(wrong_pred)\n",
    "\n",
    "# Собираем таблицу\n",
    "df_wrong = pd.DataFrame({\n",
    "    \"Text\": wrong_texts,\n",
    "    \"True Label\": wrong_true_labels,\n",
    "    \"Predicted Label\": wrong_pred_labels\n",
    "})\n",
    "\n",
    "# Показываем первые 10 ошибок\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "df_wrong.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3463e3b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
