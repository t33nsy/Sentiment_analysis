{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19b71d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 19:16:15.104112: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-18 19:16:15.315917: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744992975.400125     972 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744992975.422270     972 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744992975.565598     972 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744992975.565634     972 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744992975.565635     972 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744992975.565636     972 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-18 19:16:15.581645: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import gensim.downloader as api\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d6faa8",
   "metadata": {},
   "source": [
    "1. Загрузка GloVe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28201c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = api.load(\"glove-wiki-gigaword-100\")\n",
    "embedding_dim = 100\n",
    "max_words = 10000\n",
    "max_len = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb086cef",
   "metadata": {},
   "source": [
    "2. Загрузка датасета Sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bcf0733",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"sentiment140\", trust_remote_code=True)\n",
    "texts = dataset[\"train\"][\"text\"]\n",
    "labels = dataset[\"train\"][\"sentiment\"]\n",
    "labels = [0 if l == 0 else 1 for l in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c912ea4e",
   "metadata": {},
   "source": [
    "3. Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af2aac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418dead",
   "metadata": {},
   "source": [
    "4. Эмбеддинг матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02f9e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < max_words:\n",
    "        try:\n",
    "            embedding_matrix[i] = glove[word]\n",
    "        except KeyError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4371d7f1",
   "metadata": {},
   "source": [
    "5. Модель LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "625f8b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bastard/.local/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1744993036.343851     972 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9571 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │     \u001b[38;5;34m1,000,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> (3.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,000,000\u001b[0m (3.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> (3.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,000,000\u001b[0m (3.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words,\n",
    "              output_dim=embedding_dim,\n",
    "              input_length=max_len,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=False),\n",
    "    LSTM(128),\n",
    "    Dense(2, activation='softmax')  # 1 выход для бинарной классификации\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # бинарная кросс-энтропия\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695bdac1",
   "metadata": {},
   "source": [
    "Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5975883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"model_epoch_05.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454c2a2e",
   "metadata": {},
   "source": [
    "Callback для сохранения модели после каждой эпохи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52d5f8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=\"model_epoch_{epoch+5:02d}.h5\",\n",
    "    save_weights_only=False,  # True — сохранять только веса, False — всю модель\n",
    "    save_freq='epoch',        # сохранять после каждой эпохи\n",
    "    verbose=1                 # вывод уведомлений\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c880b41",
   "metadata": {},
   "source": [
    "6. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c4eab77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744939520.970707   11937 cuda_dnn.cc:529] Loaded cuDNN version 90800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19997/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7719 - loss: 0.4775\n",
      "Epoch 1: saving model to model_epoch_01.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 11ms/step - accuracy: 0.7719 - loss: 0.4775 - val_accuracy: 0.6634 - val_loss: 0.6181\n",
      "Epoch 2/5\n",
      "\u001b[1m19997/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8207 - loss: 0.3950\n",
      "Epoch 2: saving model to model_epoch_02.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 11ms/step - accuracy: 0.8207 - loss: 0.3950 - val_accuracy: 0.6939 - val_loss: 0.5957\n",
      "Epoch 3/5\n",
      "\u001b[1m19997/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8310 - loss: 0.3750\n",
      "Epoch 3: saving model to model_epoch_03.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 11ms/step - accuracy: 0.8310 - loss: 0.3750 - val_accuracy: 0.6470 - val_loss: 0.6639\n",
      "Epoch 4/5\n",
      "\u001b[1m19999/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8376 - loss: 0.3624\n",
      "Epoch 4: saving model to model_epoch_04.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 11ms/step - accuracy: 0.8376 - loss: 0.3624 - val_accuracy: 0.7041 - val_loss: 0.5936\n",
      "Epoch 5/5\n",
      "\u001b[1m19996/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8430 - loss: 0.3531\n",
      "Epoch 5: saving model to model_epoch_05.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 11ms/step - accuracy: 0.8430 - loss: 0.3531 - val_accuracy: 0.7249 - val_loss: 0.5579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fac44167f40>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=5, batch_size=64, validation_split=0.2, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db0db78",
   "metadata": {},
   "source": [
    "7. Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40218a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenizer.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(tokenizer.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05377653",
   "metadata": {},
   "source": [
    "Предсказывание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b775a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите текст (или 'exit' для выхода):\n",
      "Класс: Negative (уверенность: 0.72)\n",
      "\n",
      "Класс: Negative (уверенность: 0.93)\n",
      "\n",
      "Класс: Negative (уверенность: 0.77)\n",
      "\n",
      "Класс: Positive (уверенность: 0.53)\n",
      "\n",
      "Класс: Positive (уверенность: 0.51)\n",
      "\n",
      "Класс: Negative (уверенность: 0.83)\n",
      "\n",
      "Класс: Negative (уверенность: 0.83)\n",
      "\n",
      "Класс: Positive (уверенность: 0.53)\n",
      "\n",
      "Класс: Positive (уверенность: 0.53)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_names = [\"Negative\", \"Positive\"]\n",
    "print(\"Введите текст (или 'exit' для выхода):\")\n",
    "while True:\n",
    "    text = input(\">>> \").strip()\n",
    "    if text.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    # Токенизация и паддинг\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(sequence, maxlen=max_len, padding='post')\n",
    "\n",
    "    # Предсказание\n",
    "    prediction = model.predict(padded, verbose=0)\n",
    "    class_index = np.argmax(prediction)\n",
    "    confidence = float(np.max(prediction))\n",
    "\n",
    "    print(f\"Класс: {label_names[class_index]} (уверенность: {confidence:.2f})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9e5b05",
   "metadata": {},
   "source": [
    "Oh, I just love spending my entire weekend responding to emails. There’s nothing quite as thrilling as watching my inbox grow faster than my will to live. And the best part? The constant reminder that ‘this could have been an email’ after every pointless meeting. Truly, modern work culture is a masterpiece of efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d269c38a",
   "metadata": {},
   "source": [
    "Случайные ошибочные примеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9691745a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Анализ ошибок на небольшой выборке (для скорости):\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step\n",
      "\n",
      "Проанализировано 5000 примеров. Найдено 856 ошибок.\n",
      "Показываем 10 случайных примеров ошибок:\n",
      "\n",
      "Пример 1:\n",
      "Текст: @cece_newnew thanks  n I was dead serious bout me bein less entertainin den u cuz idk wat 2 do....i think ima jus freestyle it\n",
      "Истинный класс: Positive\n",
      "Предсказанный класс: Negative (уверенность: 0.58)\n",
      "--------------------------------------------------------------------------------\n",
      "Пример 2:\n",
      "Текст: @benpatrick90069 but im not waiting for him to do so...chaste=he's and undercover freak who'll unleash it on the 3rd or 4th date! \n",
      "Истинный класс: Positive\n",
      "Предсказанный класс: Negative (уверенность: 0.82)\n",
      "--------------------------------------------------------------------------------\n",
      "Пример 3:\n",
      "Текст: @michbek that's exactly how I felt when I ran outta pages in book 1 - love to say itoldyaso  have u listened to any Nathan Lowell yet?\n",
      "Истинный класс: Positive\n",
      "Предсказанный класс: Negative (уверенность: 0.75)\n",
      "--------------------------------------------------------------------------------\n",
      "Пример 4:\n",
      "Текст: Fccck the policee ruining the partying cus were to loud! Booo, Need some d kids I would be happpy as fck \n",
      "Истинный класс: Positive\n",
      "Предсказанный класс: Negative (уверенность: 0.80)\n",
      "--------------------------------------------------------------------------------\n",
      "Пример 5:\n",
      "Текст: @sabrinatan Gorgeous, I told you that your foundation has been discontinued yes? It's getting recalled on April 14  xox\n",
      "Истинный класс: Negative\n",
      "Предсказанный класс: Positive (уверенность: 0.76)\n",
      "--------------------------------------------------------------------------------\n",
      "Пример 6:\n",
      "Текст: @chantelYO haha yeah, newer haircut since sbs .. it really needed fixing haha. yeah i know  what a way to have a convo haha\n",
      "Истинный класс: Negative\n",
      "Предсказанный класс: Positive (уверенность: 0.77)\n",
      "--------------------------------------------------------------------------------\n",
      "Пример 7:\n",
      "Текст: Cleaning!! Haha... didn't go out at all this wknd!  Next wknd I will have to party twice as much!?\n",
      "Истинный класс: Negative\n",
      "Предсказанный класс: Positive (уверенность: 0.63)\n",
      "--------------------------------------------------------------------------------\n",
      "Пример 8:\n",
      "Текст: @mirafar @Aimie94 @Nadia_Fly Alamak..sorry...Spaghetti keras...hehe..and it's finished already... \n",
      "Истинный класс: Positive\n",
      "Предсказанный класс: Negative (уверенность: 0.59)\n",
      "--------------------------------------------------------------------------------\n",
      "Пример 9:\n",
      "Текст: @sdonoghuuue ohh yeahh \n",
      "Истинный класс: Positive\n",
      "Предсказанный класс: Negative (уверенность: 0.66)\n",
      "--------------------------------------------------------------------------------\n",
      "Пример 10:\n",
      "Текст: @JoaoJubett joaÃ£o  que tu tÃ¡ vagabundeando no twitter hein\n",
      "Истинный класс: Positive\n",
      "Предсказанный класс: Negative (уверенность: 0.92)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Анализ завершен. Можно продолжать работу.\n"
     ]
    }
   ],
   "source": [
    "# ========== Быстрый анализ ошибок (оптимизированная версия) ==========\n",
    "print(\"\\nАнализ ошибок на небольшой выборке (для скорости):\")\n",
    "\n",
    "# Берем только 5000 случайных примеров для анализа\n",
    "sample_size = 5000\n",
    "random_indices = np.random.choice(len(texts), sample_size, replace=False)\n",
    "sample_texts = [texts[i] for i in random_indices]\n",
    "sample_labels = np.array([labels[i] for i in random_indices])\n",
    "\n",
    "# Токенизация и паддинг\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_texts)\n",
    "X_sample = pad_sequences(sample_sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "# Получаем предсказания\n",
    "sample_pred = model.predict(X_sample, batch_size=512, verbose=1)  # Увеличиваем batch_size для скорости\n",
    "sample_pred_classes = np.argmax(sample_pred, axis=1)\n",
    "\n",
    "# Находим ошибочные предсказания\n",
    "wrong_indices = np.where(sample_pred_classes != sample_labels)[0]\n",
    "\n",
    "# Выводим 10 случайных ошибочных примеров\n",
    "num_errors_to_show = min(10, len(wrong_indices))\n",
    "selected_errors = np.random.choice(wrong_indices, num_errors_to_show, replace=False)\n",
    "\n",
    "print(f\"\\nПроанализировано {sample_size} примеров. Найдено {len(wrong_indices)} ошибок.\")\n",
    "print(f\"Показываем {num_errors_to_show} случайных примеров ошибок:\\n\")\n",
    "\n",
    "for i, idx in enumerate(selected_errors):\n",
    "    original_text = sample_texts[idx]\n",
    "    true_label = \"Negative\" if sample_labels[idx] == 0 else \"Positive\"\n",
    "    pred_label = \"Negative\" if sample_pred_classes[idx] == 0 else \"Positive\"\n",
    "    confidence = np.max(sample_pred[idx])\n",
    "    \n",
    "    print(f\"Пример {i+1}:\")\n",
    "    print(f\"Текст: {original_text}\")\n",
    "    print(f\"Истинный класс: {true_label}\")\n",
    "    print(f\"Предсказанный класс: {pred_label} (уверенность: {confidence:.2f})\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nАнализ завершен. Можно продолжать работу.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7105a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
